{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import compose\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Egg Whites</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>eggs</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Michigan Organic Kale</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Garlic Powder</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>spices seasonings</td>\n",
       "      <td>pantry</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Coconut Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>oils vinegars</td>\n",
       "      <td>pantry</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural Sweetener</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>baking ingredients</td>\n",
       "      <td>pantry</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  add_to_cart_order  reordered           product_name  \\\n",
       "0         2       33120                  1          1     Organic Egg Whites   \n",
       "1         2       28985                  2          1  Michigan Organic Kale   \n",
       "2         2        9327                  3          0          Garlic Powder   \n",
       "3         2       45918                  4          1         Coconut Butter   \n",
       "4         2       30035                  5          0      Natural Sweetener   \n",
       "\n",
       "   aisle_id  department_id               aisle  department  user_id eval_set  \\\n",
       "0        86             16                eggs  dairy eggs   202279    prior   \n",
       "1        83              4    fresh vegetables     produce   202279    prior   \n",
       "2       104             13   spices seasonings      pantry   202279    prior   \n",
       "3        19             13       oils vinegars      pantry   202279    prior   \n",
       "4        17             13  baking ingredients      pantry   202279    prior   \n",
       "\n",
       "   order_number  order_dow  order_hour_of_day  days_since_prior_order  \n",
       "0             3          5                  9                     8.0  \n",
       "1             3          5                  9                     8.0  \n",
       "2             3          5                  9                     8.0  \n",
       "3             3          5                  9                     8.0  \n",
       "4             3          5                  9                     8.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('instacart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c=df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_c.loc[(df.eval_set == 'prior')][['product_id','reordered','aisle_id','department_id','order_number',\n",
    "                                          'order_dow','order_hour_of_day','days_since_prior_order']]\n",
    "y_train=df_c.loc[(df.eval_set == 'prior')]['add_to_cart_order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipelines():\n",
    "    \"\"\"Create a pipeline for each of the following algorithms:\n",
    "    1. Logistic Regression\n",
    "    2. k-nearest neighbors (KNN) \n",
    "    3. Naive Bayes (Guassian)\n",
    "    4. Support Vector Machines (SVM)\n",
    "    5. Random Forestâ„¢ \n",
    "    \n",
    "    If appropriate, apply StandardScaler before the algorithm.   \n",
    "    Use default hyperparameters.\n",
    "    If an algorithm takes random_state then random_state=42 \n",
    "    \n",
    "    Return a list of all the pipelines.\n",
    "    \"\"\" \n",
    "    numeric_features=['product_id','reordered','aisle_id','department_id','order_number',\n",
    "                                          'order_dow','order_hour_of_day','days_since_prior_order']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='median'))])\n",
    "    \n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "    \n",
    "    LR=Pipeline([('preprocessor', preprocessor),('LogisticRegression', LogisticRegression(random_state=42))])\n",
    "    KNN=Pipeline([('preprocessor', preprocessor),('scaler', StandardScaler()),('KNeighborsClassifier', KNeighborsClassifier())])\n",
    "    NB=Pipeline([('preprocessor', preprocessor),('GaussianNB', GaussianNB())])\n",
    "    SVM=Pipeline([('preprocessor', preprocessor),('scaler', StandardScaler()), ('SVC', SVC(random_state=42))])\n",
    "    RF=Pipeline([ ('preprocessor', preprocessor),('RandomForestClassifier', RandomForestClassifier(random_state=42))])\n",
    "    \n",
    "    \n",
    "\n",
    "    pipelines=[LR,KNN,NB,SVM,RF]\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = make_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.74      0.17       977\n",
      "           2       0.10      0.27      0.15       940\n",
      "           3       0.07      0.02      0.03       895\n",
      "           4       0.00      0.00      0.00       831\n",
      "           5       0.00      0.00      0.00       768\n",
      "           6       0.00      0.00      0.00       697\n",
      "           7       0.00      0.00      0.00       627\n",
      "           8       0.00      0.00      0.00       555\n",
      "           9       0.00      0.00      0.00       492\n",
      "          10       0.00      0.00      0.00       433\n",
      "          11       0.00      0.00      0.00       369\n",
      "          12       0.00      0.00      0.00       309\n",
      "          13       0.00      0.00      0.00       280\n",
      "          14       0.00      0.00      0.00       248\n",
      "          15       0.00      0.00      0.00       212\n",
      "          16       0.00      0.00      0.00       185\n",
      "          17       0.00      0.00      0.00       164\n",
      "          18       0.00      0.00      0.00       146\n",
      "          19       0.00      0.00      0.00       125\n",
      "          20       0.00      0.00      0.00       110\n",
      "          21       0.00      0.00      0.00        98\n",
      "          22       0.00      0.00      0.00        87\n",
      "          23       0.00      0.00      0.00        75\n",
      "          24       0.00      0.00      0.00        66\n",
      "          25       0.00      0.00      0.00        56\n",
      "          26       0.00      0.00      0.00        40\n",
      "          27       0.00      0.00      0.00        34\n",
      "          28       0.00      0.00      0.00        28\n",
      "          29       0.00      0.00      0.00        24\n",
      "          30       0.00      0.00      0.00        20\n",
      "          31       0.00      0.00      0.00        19\n",
      "          32       0.00      0.00      0.00        15\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00        12\n",
      "          35       0.00      0.00      0.00         9\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         5\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.04      0.02     10000\n",
      "weighted avg       0.03      0.10      0.03     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.77      0.39       977\n",
      "           2       0.26      0.56      0.36       940\n",
      "           3       0.30      0.46      0.36       895\n",
      "           4       0.28      0.34      0.31       831\n",
      "           5       0.29      0.27      0.28       768\n",
      "           6       0.32      0.24      0.28       697\n",
      "           7       0.30      0.20      0.24       627\n",
      "           8       0.38      0.19      0.25       555\n",
      "           9       0.32      0.14      0.19       492\n",
      "          10       0.35      0.12      0.18       433\n",
      "          11       0.36      0.09      0.14       369\n",
      "          12       0.34      0.09      0.15       309\n",
      "          13       0.34      0.06      0.11       280\n",
      "          14       0.47      0.06      0.11       248\n",
      "          15       0.38      0.06      0.10       212\n",
      "          16       0.24      0.03      0.06       185\n",
      "          17       0.12      0.01      0.02       164\n",
      "          18       0.33      0.03      0.05       146\n",
      "          19       0.22      0.02      0.03       125\n",
      "          20       0.38      0.05      0.08       110\n",
      "          21       0.40      0.02      0.04        98\n",
      "          22       0.27      0.05      0.08        87\n",
      "          23       0.00      0.00      0.00        75\n",
      "          24       0.00      0.00      0.00        66\n",
      "          25       0.00      0.00      0.00        56\n",
      "          26       0.00      0.00      0.00        40\n",
      "          27       0.00      0.00      0.00        34\n",
      "          28       0.00      0.00      0.00        28\n",
      "          29       0.00      0.00      0.00        24\n",
      "          30       0.00      0.00      0.00        20\n",
      "          31       0.00      0.00      0.00        19\n",
      "          32       0.00      0.00      0.00        15\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00        12\n",
      "          35       0.00      0.00      0.00         9\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         5\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.28     10000\n",
      "   macro avg       0.15      0.08      0.08     10000\n",
      "weighted avg       0.29      0.28      0.24     10000\n",
      "\n",
      "GaussianNB \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.61      0.18       977\n",
      "           2       0.10      0.27      0.15       940\n",
      "           3       0.09      0.13      0.11       895\n",
      "           4       0.08      0.02      0.03       831\n",
      "           5       0.06      0.00      0.00       768\n",
      "           6       0.14      0.00      0.00       697\n",
      "           7       0.10      0.01      0.02       627\n",
      "           8       0.06      0.02      0.03       555\n",
      "           9       0.40      0.00      0.01       492\n",
      "          10       0.00      0.00      0.00       433\n",
      "          11       0.00      0.00      0.00       369\n",
      "          12       0.00      0.00      0.00       309\n",
      "          13       0.00      0.00      0.00       280\n",
      "          14       0.00      0.00      0.00       248\n",
      "          15       0.00      0.00      0.00       212\n",
      "          16       0.00      0.00      0.00       185\n",
      "          17       0.00      0.00      0.00       164\n",
      "          18       0.00      0.00      0.00       146\n",
      "          19       0.00      0.00      0.00       125\n",
      "          20       0.00      0.00      0.00       110\n",
      "          21       0.00      0.00      0.00        98\n",
      "          22       0.00      0.00      0.00        87\n",
      "          23       0.00      0.00      0.00        75\n",
      "          24       0.00      0.00      0.00        66\n",
      "          25       0.00      0.00      0.00        56\n",
      "          26       0.00      0.00      0.00        40\n",
      "          27       0.00      0.00      0.00        34\n",
      "          28       0.00      0.00      0.00        28\n",
      "          29       0.00      0.00      0.00        24\n",
      "          30       0.00      0.00      0.00        20\n",
      "          31       0.00      0.00      0.00        19\n",
      "          32       0.00      0.00      0.00        15\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00        12\n",
      "          35       0.00      0.00      0.00         9\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         5\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.15      0.50      0.24         4\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.05      0.06      0.04     10000\n",
      "weighted avg       0.08      0.10      0.05     10000\n",
      "\n",
      "SVC \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.59      0.22       977\n",
      "           2       0.16      0.30      0.21       940\n",
      "           3       0.14      0.29      0.19       895\n",
      "           4       0.15      0.13      0.14       831\n",
      "           5       0.12      0.14      0.13       768\n",
      "           6       0.15      0.05      0.08       697\n",
      "           7       0.18      0.02      0.04       627\n",
      "           8       0.00      0.00      0.00       555\n",
      "           9       1.00      0.00      0.00       492\n",
      "          10       0.00      0.00      0.00       433\n",
      "          11       0.00      0.00      0.00       369\n",
      "          12       0.00      0.00      0.00       309\n",
      "          13       0.00      0.00      0.00       280\n",
      "          14       0.00      0.00      0.00       248\n",
      "          15       0.00      0.00      0.00       212\n",
      "          16       0.00      0.00      0.00       185\n",
      "          17       0.00      0.00      0.00       164\n",
      "          18       0.00      0.00      0.00       146\n",
      "          19       0.00      0.00      0.00       125\n",
      "          20       0.00      0.00      0.00       110\n",
      "          21       0.00      0.00      0.00        98\n",
      "          22       0.00      0.00      0.00        87\n",
      "          23       0.00      0.00      0.00        75\n",
      "          24       0.00      0.00      0.00        66\n",
      "          25       0.00      0.00      0.00        56\n",
      "          26       0.00      0.00      0.00        40\n",
      "          27       0.00      0.00      0.00        34\n",
      "          28       0.00      0.00      0.00        28\n",
      "          29       0.00      0.00      0.00        24\n",
      "          30       0.00      0.00      0.00        20\n",
      "          31       0.00      0.00      0.00        19\n",
      "          32       0.00      0.00      0.00        15\n",
      "          33       0.00      0.00      0.00        14\n",
      "          34       0.00      0.00      0.00        12\n",
      "          35       0.00      0.00      0.00         9\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         5\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.14     10000\n",
      "   macro avg       0.04      0.03      0.02     10000\n",
      "weighted avg       0.13      0.14      0.09     10000\n",
      "\n",
      "RandomForestClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.99      0.98       977\n",
      "           2       0.98      0.99      0.99       940\n",
      "           3       0.98      0.99      0.98       895\n",
      "           4       0.98      0.99      0.99       831\n",
      "           5       0.99      0.98      0.98       768\n",
      "           6       0.98      0.98      0.98       697\n",
      "           7       0.99      0.99      0.99       627\n",
      "           8       0.99      0.97      0.98       555\n",
      "           9       0.98      0.99      0.99       492\n",
      "          10       0.99      0.98      0.99       433\n",
      "          11       0.99      0.97      0.98       369\n",
      "          12       0.98      0.99      0.99       309\n",
      "          13       0.99      0.99      0.99       280\n",
      "          14       0.99      0.99      0.99       248\n",
      "          15       0.99      0.98      0.98       212\n",
      "          16       0.99      0.98      0.98       185\n",
      "          17       0.99      0.98      0.99       164\n",
      "          18       0.97      0.98      0.98       146\n",
      "          19       1.00      0.98      0.99       125\n",
      "          20       0.99      0.97      0.98       110\n",
      "          21       0.99      0.97      0.98        98\n",
      "          22       0.99      0.98      0.98        87\n",
      "          23       1.00      0.97      0.99        75\n",
      "          24       0.98      0.98      0.98        66\n",
      "          25       0.98      1.00      0.99        56\n",
      "          26       1.00      1.00      1.00        40\n",
      "          27       1.00      0.94      0.97        34\n",
      "          28       1.00      1.00      1.00        28\n",
      "          29       0.96      0.96      0.96        24\n",
      "          30       0.95      1.00      0.98        20\n",
      "          31       1.00      1.00      1.00        19\n",
      "          32       1.00      1.00      1.00        15\n",
      "          33       1.00      1.00      1.00        14\n",
      "          34       1.00      0.92      0.96        12\n",
      "          35       1.00      0.78      0.88         9\n",
      "          36       1.00      0.88      0.93         8\n",
      "          37       1.00      1.00      1.00         5\n",
      "          38       0.83      1.00      0.91         5\n",
      "          39       1.00      1.00      1.00         4\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.99      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for pipe in pipelines:\n",
    "    print(pipe.steps[-1][0],'\\n',classification_report(y_train, pipe.predict(X_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
